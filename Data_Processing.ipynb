{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6ZFuSJJ-WAE"
      },
      "outputs": [],
      "source": [
        "pip install geopandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of initial fire and non-fire datapoints\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Load the shapefile containing the Riverside County boundaries\n",
        "riverside_county = gpd.read_file(\"/content/Riverside County/Riverside_County.shp\")\n",
        "\n",
        "# Filter out any points that fall outside of the Riverside County boundaries\n",
        "fire_data = pd.read_excel(\"/content/Fire Data, 18-22.xlsx\")\n",
        "fire_data = fire_data[(fire_data['latitude'] >= riverside_county.bounds['miny'].min()) &\n",
        "                      (fire_data['latitude'] <= riverside_county.bounds['maxy'].max()) &\n",
        "                      (fire_data['longitude'] >= riverside_county.bounds['minx'].min()) &\n",
        "                      (fire_data['longitude'] <= riverside_county.bounds['maxx'].max())]\n",
        "\n",
        "# Randomly generate 250 points within the filtered Riverside County boundaries for the no fire datapoints\n",
        "npoints = 250;\n",
        "no_fire_data = pd.DataFrame(np.zeros((npoints, 3)), columns=['Date', 'longitude', 'latitude'])\n",
        "no_fire_data['longitude'] = np.random.uniform(riverside_county.bounds['minx'].min(), riverside_county.bounds['maxx'].max(), npoints)\n",
        "no_fire_data['latitude'] = np.random.uniform(riverside_county.bounds['miny'].min(), riverside_county.bounds['maxy'].max(), npoints)\n",
        "\n",
        "# Generate random dates within a range of dates for the no fire datapoints\n",
        "start_date = pd.to_datetime('2022-01-01')\n",
        "end_date = pd.to_datetime('2022-12-31')\n",
        "no_fire_data['Date'] = [random.choice(pd.date_range(start=start_date, end=end_date)).date() for _ in range(npoints)]\n",
        "\n",
        "# Randomly select 250 fire datapoints from the filtered fire data\n",
        "fire_data = fire_data.sample(n=npoints)\n",
        "\n",
        "# Add a new boolean column to indicate whether each point represents a fire or not\n",
        "fire_data['fire'] = True\n",
        "no_fire_data['fire'] = False\n",
        "\n",
        "# Combine the no fire datapoints and fire datapoints into a single dataset\n",
        "data = pd.concat([no_fire_data, fire_data], ignore_index=True)"
      ],
      "metadata": {
        "id": "ndFHqoY5_F0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "y0MTeNwxPvAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_excel(\"train_test.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "bzMP6wtaASgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of Shapefile with initial points\n",
        "\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Load the xlsx file into a Pandas DataFrame\n",
        "df = pd.read_excel('/content/train_test.xlsx')\n",
        "\n",
        "# Convert the date field to a string field\n",
        "df['Date'] = df['Date'].astype(str)\n",
        "\n",
        "# Create a Point geometry column using the Longitude and Latitude columns\n",
        "geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\n",
        "\n",
        "# Convert the DataFrame to a GeoDataFrame\n",
        "gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
        "\n",
        "# Save the GeoDataFrame as a shapefile with accompanying dbf and shx files\n",
        "gdf.to_file('train_test_shape')"
      ],
      "metadata": {
        "id": "cK_uOQZ_BH3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://code.earthengine.google.com/fb4d6517da6bb886cf946f77bc52800e"
      ],
      "metadata": {
        "id": "elLrU4K4KaBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning a Weather Station to each datapoint\n",
        "\n",
        "import pandas as pd\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "\n",
        "# Load the fire and weather datasets\n",
        "fire_data = pd.read_csv('/content/NDVI_Values.csv')\n",
        "weather_data = pd.read_excel('/content/Weather Station Names.xlsx')\n",
        "\n",
        "# Define a function to calculate the distance between two sets of coordinates\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6372.8\n",
        "\n",
        "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "\n",
        "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
        "    c = 2 * asin(sqrt(a))\n",
        "\n",
        "    distance_km = R * c\n",
        "    return distance_km\n",
        "\n",
        "# Loop through each data point in the fire dataset\n",
        "closest_stations = []\n",
        "for index, row in fire_data.iterrows():\n",
        "    min_distance = float('inf')\n",
        "    closest_station = None\n",
        "\n",
        "    # Loop through each weather station coordinate in the weather dataset\n",
        "    for windex, wrow in weather_data.iterrows():\n",
        "        distance = haversine(row['latitude'], row['longitude'], wrow['Latitude'], wrow['Longitude'])\n",
        "\n",
        "        # Keep track of the closest weather station\n",
        "        if distance < min_distance:\n",
        "            min_distance = distance\n",
        "            closest_station = wrow['station_name']\n",
        "\n",
        "    closest_stations.append(closest_station)\n",
        "\n",
        "# Add the closest weather station name as a new column in the fire dataset\n",
        "fire_data['closest_weather_station'] = closest_stations\n",
        "\n",
        "# Save the updated fire dataset to a new xlsx file\n",
        "fire_data.to_excel('fire_data_with_closest_weather_station.xlsx', index=False)"
      ],
      "metadata": {
        "id": "Fd9oRT5tCw4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning Weather features to each datapoint\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import datetime as dt\n",
        "\n",
        "# read in fire dataset\n",
        "fire_data = pd.read_excel('/content/fire_data_with_closest_weather_station.xlsx')\n",
        "\n",
        "# create empty dataframe to hold weather data\n",
        "weather_data = pd.DataFrame(columns=['Date', 'Avg Temperature', 'Max Temperature', 'Min Temperature', 'Precipitation', 'Latitude', 'Longitude', 'closest_weather_station'])\n",
        "\n",
        "# loop through weather files\n",
        "for filename in os.listdir('/content/Individual Weather Stations'):\n",
        "    if filename.endswith('.xlsx'):\n",
        "        # read in weather data\n",
        "        weather = pd.read_excel(os.path.join('/content/Individual Weather Stations', filename))\n",
        "        # convert Date column to datetime format\n",
        "        weather['Date'] = pd.to_datetime(weather['Date'], format='%m/%d/%Y')\n",
        "        # extract weather station name from filename\n",
        "        station_name = filename[:-5]\n",
        "        # add station name as a column to weather data\n",
        "        weather['closest_weather_station'] = station_name\n",
        "        # append weather data to weather_data dataframe\n",
        "        weather_data = pd.concat([weather_data, weather], ignore_index=True)\n",
        "\n",
        "# convert Date column in fire_data to datetime format\n",
        "fire_data['Date'] = pd.to_datetime(fire_data['Date'], format='%Y-%m-%d')\n",
        "\n",
        "# loop through rows in fire_data and find corresponding weather data\n",
        "for i, row in fire_data.iterrows():\n",
        "    # extract latitude, longitude, and date from row\n",
        "    lat = row['latitude']\n",
        "    lon = row['longitude']\n",
        "    date = row['Date']\n",
        "    # calculate distances between fire location and weather stations\n",
        "    distances = ((weather_data['Latitude'] - lat)**2 + (weather_data['Longitude'] - lon)**2)**0.5\n",
        "    # find closest weather station\n",
        "    closest_station = weather_data.loc[distances.idxmin(), 'closest_weather_station']\n",
        "    # find weather data for closest station and closest date\n",
        "    closest_weather = weather_data.loc[(weather_data['closest_weather_station'] == closest_station) & (weather_data['Date'] - date >= dt.timedelta(days=0))].iloc[0]\n",
        "    # add weather data to fire_data\n",
        "    fire_data.loc[i, 'Avg Temperature'] = closest_weather['Avg Temperature']\n",
        "    fire_data.loc[i, 'Max Temperature'] = closest_weather['Max Temperature']\n",
        "    fire_data.loc[i, 'Min Temperature'] = closest_weather['Min Temperature']\n",
        "    fire_data.loc[i, 'Precipitation'] = closest_weather['Precipitation']\n",
        "    fire_data.loc[i, 'closest_weather_station'] = closest_station\n",
        "\n",
        "# write updated fire data to new file\n",
        "fire_data.to_excel('/content/fire_data_with_weather.xlsx', index=False)"
      ],
      "metadata": {
        "id": "jGtJSB-FGSJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the xlsx file\n",
        "df = pd.read_excel('/content/fire_data_with_weather.xlsx')\n",
        "\n",
        "# Extract the required columns\n",
        "df = df[['fire', 'nd', 'Avg Temperature', 'Max Temperature', 'Min Temperature', 'Precipitation']]\n",
        "\n",
        "# Rename the columns\n",
        "df = df.rename(columns={'nd': 'NDVI', 'fire': 'Fire'})\n",
        "\n",
        "# Convert the Fire column to boolean values\n",
        "df['Fire'] = df['Fire'].astype(bool)\n",
        "\n",
        "# Save the new csv file\n",
        "df.to_csv('fire_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "E1Ffi7HTeALj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(\"/content/fire_dataset.csv\")\n",
        "\n",
        "# Remove rows with NaN or missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Save the cleaned dataset as a new CSV file\n",
        "data.to_csv(\"fire_dataset_normal.csv\", index=False)"
      ],
      "metadata": {
        "id": "xtkW3tn4e5fI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}